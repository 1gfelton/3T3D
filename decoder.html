<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Transformer Decoder Architecture</title>
    <style>
        body {
            font-family: 'Arial', sans-serif;
            margin: 20px;
            background-color: #f8f9fa;
        }
        .diagram-container {
            background: white;
            border-radius: 10px;
            padding: 20px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            overflow-x: auto;
        }
        .title {
            font-size: 22px;
            font-weight: bold;
            text-anchor: middle;
            fill: #2c3e50;
        }
        .subtitle {
            font-size: 14px;
            font-weight: bold;
            fill: #34495e;
        }
        .layer-label {
            font-size: 12px;
            fill: #2c3e50;
            font-weight: 600;
        }
        .tensor-shape {
            font-size: 10px;
            fill: #7f8c8d;
            font-family: 'Courier New', monospace;
        }
        .operation-label {
            font-size: 11px;
            fill: #34495e;
            font-weight: 500;
        }
        .attention-box {
            fill: #fef3c7;
            stroke: #f59e0b;
            stroke-width: 2;
        }
        .norm-box {
            fill: #ddd6fe;
            stroke: #8b5cf6;
            stroke-width: 1.5;
        }
        .ffn-box {
            fill: #dcfce7;
            stroke: #16a34a;
            stroke-width: 2;
        }
        .input-output-box {
            fill: #ecf0f1;
            stroke: #95a5a6;
            stroke-width: 2;
        }
        .residual-connection {
            stroke: #e74c3c;
            stroke-width: 2;
            fill: none;
            stroke-dasharray: 5,5;
        }
        .data-flow {
            stroke: #3498db;
            stroke-width: 2;
            fill: none;
            marker-end: url(#arrowhead);
        }
        .attention-flow {
            stroke: #f39c12;
            stroke-width: 1.5;
            fill: none;
            marker-end: url(#arrowhead-small);
        }
    </style>
</head>
<body>
    <div class="diagram-container">
        <svg width="1000" height="900" viewBox="0 0 1000 900">
            <!-- Define arrow markers -->
            <defs>
                <marker id="arrowhead" markerWidth="10" markerHeight="7" 
                        refX="10" refY="3.5" orient="auto">
                    <polygon points="0 0, 10 3.5, 0 7" fill="#3498db" />
                </marker>
                <marker id="arrowhead-small" markerWidth="8" markerHeight="5" 
                        refX="8" refY="2.5" orient="auto">
                    <polygon points="0 0, 8 2.5, 0 5" fill="#f39c12" />
                </marker>
            </defs>
            
            <!-- Title -->
            <text x="500" y="30" class="title">6-Layer Transformer Decoder Architecture</text>
            <text x="500" y="50" text-anchor="middle" class="subtitle">Self-Attention Refinement for Multi-View Fusion</text>
            
            <!-- Input -->
            <rect x="400" y="80" width="200" height="40" class="input-output-box" rx="5"/>
            <text x="500" y="95" text-anchor="middle" class="operation-label">Input: Fused Multi-View Features</text>
            <text x="500" y="108" text-anchor="middle" class="operation-label">+ 2D Positional Encoding</text>
            <text x="500" y="115" text-anchor="middle" class="tensor-shape">[B, 256, 512]</text>
            
            <!-- Layer 1 detailed breakdown -->
            <text x="50" y="160" class="subtitle">Decoder Layer 1 (Detailed View)</text>
            
            <!-- Layer Norm 1 -->
            <rect x="430" y="180" width="140" height="30" class="norm-box" rx="3"/>
            <text x="500" y="195" text-anchor="middle" class="operation-label">Layer Norm (Pre-Norm)</text>
            <text x="500" y="205" text-anchor="middle" class="tensor-shape">[B, 256, 512]</text>
            
            <!-- Multi-Head Self-Attention -->
            <rect x="350" y="230" width="300" height="80" class="attention-box" rx="5"/>
            <text x="500" y="250" text-anchor="middle" class="operation-label">Multi-Head Self-Attention</text>
            <text x="500" y="265" text-anchor="middle" class="operation-label">8 Heads × 64D = 512D</text>
            <text x="500" y="280" text-anchor="middle" class="operation-label">Q = K = V = same sequence</text>
            <text x="500" y="295" text-anchor="middle" class="tensor-shape">[B, 256, 512] → [B, 256, 512]</text>
            
            <!-- Attention mechanism detail -->
            <text x="370" y="325" class="operation-label">Query</text>
            <text x="460" y="325" class="operation-label">Key</text>
            <text x="540" y="325" class="operation-label">Value</text>
            <path d="M 390 320 Q 500 340 550 320" class="attention-flow"/>
            <path d="M 480 320 Q 500 340 520 320" class="attention-flow"/>
            
            <!-- Residual Connection 1 -->
            <path d="M 350 200 Q 320 200 320 270 Q 320 340 350 340" class="residual-connection"/>
            <text x="280" y="270" class="operation-label" transform="rotate(-90, 280, 270)">Residual</text>
            
            <!-- Add & Norm 1 -->
            <circle cx="500" cy="340" r="15" fill="#e74c3c" stroke="#c0392b" stroke-width="2"/>
            <text x="500" y="345" text-anchor="middle" class="operation-label" fill="white">+</text>
            
            <!-- Layer Norm 2 -->
            <rect x="430" y="370" width="140" height="30" class="norm-box" rx="3"/>
            <text x="500" y="385" text-anchor="middle" class="operation-label">Layer Norm</text>
            <text x="500" y="395" text-anchor="middle" class="tensor-shape">[B, 256, 512]</text>
            
            <!-- Feed Forward Network -->
            <rect x="380" y="420" width="240" height="60" class="ffn-box" rx="5"/>
            <text x="500" y="440" text-anchor="middle" class="operation-label">Feed Forward Network</text>
            <text x="500" y="455" text-anchor="middle" class="operation-label">512 → 2048 → 512</text>
            <text x="500" y="470" text-anchor="middle" class="operation-label">ReLU Activation + Dropout</text>
            
            <!-- Residual Connection 2 -->
            <path d="M 650 385 Q 680 385 680 450 Q 680 515 650 515" class="residual-connection"/>
            <text x="720" y="450" class="operation-label" transform="rotate(90, 720, 450)">Residual</text>
            
            <!-- Add & Norm 2 -->
            <circle cx="500" cy="515" r="15" fill="#e74c3c" stroke="#c0392b" stroke-width="2"/>
            <text x="500" y="520" text-anchor="middle" class="operation-label" fill="white">+</text>
            
            <!-- Layers 2-6 (Simplified) -->
            <text x="50" y="580" class="subtitle">Layers 2-6 (Same Structure)</text>
            
            <rect x="100" y="600" width="120" height="40" class="attention-box" rx="3"/>
            <text x="160" y="615" text-anchor="middle" class="operation-label">Layer 2</text>
            <text x="160" y="630" text-anchor="middle" class="operation-label">Self-Attention</text>
            
            <rect x="240" y="600" width="120" height="40" class="attention-box" rx="3"/>
            <text x="300" y="615" text-anchor="middle" class="operation-label">Layer 3</text>
            <text x="300" y="630" text-anchor="middle" class="operation-label">Self-Attention</text>
            
            <rect x="380" y="600" width="120" height="40" class="attention-box" rx="3"/>
            <text x="440" y="615" text-anchor="middle" class="operation-label">Layer 4</text>
            <text x="440" y="630" text-anchor="middle" class="operation-label">Self-Attention</text>
            
            <rect x="520" y="600" width="120" height="40" class="attention-box" rx="3"/>
            <text x="580" y="615" text-anchor="middle" class="operation-label">Layer 5</text>
            <text x="580" y="630" text-anchor="middle" class="operation-label">Self-Attention</text>
            
            <rect x="660" y="600" width="120" height="40" class="attention-box" rx="3"/>
            <text x="720" y="615" text-anchor="middle" class="operation-label">Layer 6</text>
            <text x="720" y="630" text-anchor="middle" class="operation-label">Self-Attention</text>
            
            <!-- Flow arrows between layers -->
            <path d="M 220 620 L 235 620" class="data-flow"/>
            <path d="M 360 620 L 375 620" class="data-flow"/>
            <path d="M 500 620 L 515 620" class="data-flow"/>
            <path d="M 640 620 L 655 620" class="data-flow"/>
            
            <!-- Output -->
            <rect x="400" y="680" width="200" height="40" class="input-output-box" rx="5"/>
            <text x="500" y="695" text-anchor="middle" class="operation-label">Output: Refined Features</text>
            <text x="500" y="710" text-anchor="middle" class="tensor-shape">[B, 256, 512]</text>
            
            <!-- Main data flow arrows -->
            <path d="M 500 120 L 500 175" class="data-flow"/>
            <path d="M 500 210 L 500 225" class="data-flow"/>
            <path d="M 500 355 L 500 365" class="data-flow"/>
            <path d="M 500 400 L 500 415" class="data-flow"/>
            <path d="M 500 530 L 500 595" class="data-flow"/>
            <path d="M 720 640 L 720 665 L 500 665 L 500 675" class="data-flow"/>
            
            <!-- Key architectural details -->
            <text x="50" y="760" class="subtitle">Key Architecture Details</text>
            <text x="50" y="780" class="layer-label">• Self-Attention: Q = K = V = same input sequence</text>
            <text x="50" y="795" class="layer-label">• Pre-Norm Architecture: LayerNorm before operations</text>
            <text x="50" y="810" class="layer-label">• Residual Connections: Around attention and FFN blocks</text>
            <text x="50" y="825" class="layer-label">• 8 Attention Heads: 512D ÷ 8 = 64D per head</text>
            <text x="50" y="840" class="layer-label">• FFN Expansion: 512 → 2048 → 512 with ReLU</text>
            <text x="50" y="855" class="layer-label">• Purpose: Global spatial reasoning and feature refinement</text>
            
            <!-- Attention mechanism visualization -->
            <text x="750" y="180" class="subtitle">Self-Attention Pattern</text>
            <rect x="750" y="200" width="200" height="120" fill="#fff2cc" stroke="#d6b656" stroke-width="1" rx="3"/>
            <text x="850" y="220" text-anchor="middle" class="operation-label">Each patch attends to</text>
            <text x="850" y="235" text-anchor="middle" class="operation-label">ALL other patches</text>
            
            <!-- Grid representation -->
            <g transform="translate(780, 250)">
                <!-- 4x4 grid representing patches -->
                <rect x="0" y="0" width="15" height="15" fill="#3498db" opacity="0.8"/>
                <rect x="20" y="0" width="15" height="15" fill="#ecf0f1" stroke="#bdc3c7"/>
                <rect x="40" y="0" width="15" height="15" fill="#ecf0f1" stroke="#bdc3c7"/>
                <rect x="60" y="0" width="15" height="15" fill="#ecf0f1" stroke="#bdc3c7"/>
                
                <rect x="0" y="20" width="15" height="15" fill="#ecf0f1" stroke="#bdc3c7"/>
                <rect x="20" y="20" width="15" height="15" fill="#ecf0f1" stroke="#bdc3c7"/>
                <rect x="40" y="20" width="15" height="15" fill="#ecf0f1" stroke="#bdc3c7"/>
                <rect x="60" y="20" width="15" height="15" fill="#ecf0f1" stroke="#bdc3c7"/>
                
                <rect x="0" y="40" width="15" height="15" fill="#ecf0f1" stroke="#bdc3c7"/>
                <rect x="20" y="40" width="15" height="15" fill="#ecf0f1" stroke="#bdc3c7"/>
                <rect x="40" y="40" width="15" height="15" fill="#ecf0f1" stroke="#bdc3c7"/>
                <rect x="60" y="40" width="15" height="15" fill="#ecf0f1" stroke="#bdc3c7"/>
                
                <rect x="0" y="60" width="15" height="15" fill="#ecf0f1" stroke="#bdc3c7"/>
                <rect x="20" y="60" width="15" height="15" fill="#ecf0f1" stroke="#bdc3c7"/>
                <rect x="40" y="60" width="15" height="15" fill="#ecf0f1" stroke="#bdc3c7"/>
                <rect x="60" y="60" width="15" height="15" fill="#ecf0f1" stroke="#bdc3c7"/>
                
                <!-- Attention lines from blue patch to others -->
                <line x1="7.5" y1="7.5" x2="27.5" y2="7.5" stroke="#e74c3c" stroke-width="1" opacity="0.6"/>
                <line x1="7.5" y1="7.5" x2="47.5" y2="7.5" stroke="#e74c3c" stroke-width="1" opacity="0.6"/>
                <line x1="7.5" y1="7.5" x2="67.5" y2="7.5" stroke="#e74c3c" stroke-width="1" opacity="0.6"/>
                <line x1="7.5" y1="7.5" x2="7.5" y2="27.5" stroke="#e74c3c" stroke-width="1" opacity="0.6"/>
                <line x1="7.5" y1="7.5" x2="27.5" y2="27.5" stroke="#e74c3c" stroke-width="1" opacity="0.6"/>
                <line x1="7.5" y1="7.5" x2="47.5" y2="47.5" stroke="#e74c3c" stroke-width="1" opacity="0.6"/>
            </g>
            
            <text x="850" y="300" text-anchor="middle" class="operation-label" font-size="10">16×16 = 256 patches</text>
            <text x="850" y="315" text-anchor="middle" class="operation-label" font-size="10">Global receptive field</text>
        </svg>
    </div>
</body>
</html>
